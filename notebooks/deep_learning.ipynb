{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 18:05:43.080531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:05:43.080563: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "import keras\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras import regularizers, callbacks\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Flatten, Embedding, Activation, GRUCell, LSTMCell,SimpleRNNCell\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, Conv1D, SimpleRNN, GRU, LSTM, CuDNNLSTM, CuDNNGRU, Conv2D\n",
    "from keras.layers import LeakyReLU, PReLU, ThresholdedReLU, ELU\n",
    "from keras.layers import BatchNormalization, TimeDistributed, Bidirectional\n",
    "from keras.layers import Wrapper\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.utils import np_utils\n",
    "from keras import constraints, initializers, regularizers\n",
    "import keras.losses\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_rnn_model(input_dim, output_dim=29):\n",
    "    # Input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Recurrent layer\n",
    "    simp_rnn = GRU(output_dim, return_sequences=True, \n",
    "                 implementation=2, name='rnn')(input_data)\n",
    "    # Softmax Activation Layer\n",
    "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
    "    # Specifying the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 161)]       0         \n",
      "                                                                 \n",
      " rnn (GRU)                   (None, None, 29)          16704     \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 29)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,704\n",
      "Trainable params: 16,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 18:06:51.132541: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-07 18:06:51.132583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-60-46.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-07 18:06:51.132991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_0 = regular_rnn_model(input_dim=161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "from prep import prep\n",
    "from AudioGenerator import AudioGenerator\n",
    "audio_gen = AudioGenerator(spectrogram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel_mitiku/root/Speech-to-Text/notebooks/../scripts/AudioGenerator.py:483: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "583/583 [==============================] - 149s 251ms/step - loss: 1748.3467 - val_loss: 1593.5072 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "583/583 [==============================] - 148s 255ms/step - loss: 1044.2191 - val_loss: 833.3390 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "583/583 [==============================] - 149s 255ms/step - loss: 888.0744 - val_loss: 815.0851 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "583/583 [==============================] - 148s 254ms/step - loss: 885.6637 - val_loss: 812.7409 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "583/583 [==============================] - 149s 255ms/step - loss: 885.4000 - val_loss: 814.3174 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "583/583 [==============================] - 149s 256ms/step - loss: 885.1489 - val_loss: 814.3876 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "audio_gen.train_model(input_to_softmax=model_0, \n",
    "            pickle_path='model_0.pickle', \n",
    "            save_model_path='model_0.h5',\n",
    "            spectrogram=True,\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brnn_tdd_model(input_dim, units, activation, output_dim=29):\n",
    "    # Input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Bidirectional recurrent layer\n",
    "    brnn = Bidirectional(LSTM(units, activation=activation, \n",
    "        return_sequences=True, implementation=2, name='brnn'))(input_data)\n",
    "    # TimeDistributed Dense layer\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(brnn)\n",
    "    # Softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specifying the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 161)]       0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 400)        579200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 29)         11629     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 29)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 590,829\n",
      "Trainable params: 590,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_2 = brnn_tdd_model(input_dim=161, units=200, activation='relu') # 161 for Spectrogram/13 for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel_mitiku/root/Speech-to-Text/notebooks/../scripts/AudioGenerator.py:483: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/583 [..............................] - ETA: 23:58 - loss: 6514.1245Batch 1: Invalid loss, terminating training\n",
      "583/583 [==============================] - 29s 45ms/step - loss: nan - val_loss: nan - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "audio_gen.train_model(input_to_softmax=model_2, \n",
    "            pickle_path='model_2.pickle', \n",
    "            save_model_path='model_2.h5', \n",
    "            spectrogram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + Deeper Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_deep_brnn_tdd_model(input_dim, filters, activation, kernel_size, conv_stride,\n",
    "    conv_border_mode, recur_layers, units, output_dim=29):\n",
    "    # Input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Convolutional layer\n",
    "    conv_1d = Conv1D(filters, kernel_size, \n",
    "                     strides=conv_stride, \n",
    "                     padding=conv_border_mode,\n",
    "                     activation=activation,\n",
    "                     name='conv1d')(input_data)\n",
    "    # Batch normalization\n",
    "    bn_cnn = BatchNormalization()(conv_1d)\n",
    "    # Bidirectional recurrent layer\n",
    "    brnn = Bidirectional(GRU(units, activation=activation, \n",
    "        return_sequences=True, name='brnn'))(bn_cnn)\n",
    "    # Batch normalization \n",
    "    bn_rnn = BatchNormalization()(brnn)\n",
    "    # Loop for additional layers\n",
    "    for i in range(recur_layers - 1):\n",
    "        name = 'brnn_' + str(i + 1)\n",
    "        brnn = Bidirectional(GRU(units, activation=activation, \n",
    "        return_sequences=True, implementation=2, name=name))(bn_rnn)\n",
    "        bn_rnn = BatchNormalization()(brnn)\n",
    "    # TimeDistributed Dense layer\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\n",
    "    # Softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specifying the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: audio_gen.cnn_output_length(\n",
    "        x, kernel_size, conv_border_mode, conv_stride)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 161)]       0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 200)         354400    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 200)        800       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 400)        482400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 400)        1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 400)        722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 400)        1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 29)         11629     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 29)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,574,829\n",
      "Trainable params: 1,572,829\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_3 = cnn_deep_brnn_tdd_model(input_dim=161, # 161 for Spectrogram/13 for MFCC\n",
    "                                  filters=200,\n",
    "                                  activation='relu',\n",
    "                                  kernel_size=11, \n",
    "                                  conv_stride=2,\n",
    "                                  conv_border_mode='valid',\n",
    "                                  recur_layers=2,\n",
    "                                  units=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_gen.train_model(input_to_softmax=model_3, \n",
    "            pickle_path='model_3.pickle', \n",
    "            save_model_path='model_3.h5', \n",
    "            spectrogram=True) # True for Spectrogram/False for MFCC"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c2b8563932708ac4f64e3bc4797ea8eb43fc7530baa7f01daadf5b46d7b1fd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
